{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac817bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.timeanddate.com/weather/\")\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d88094d",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d789bb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "td_tags = soup.find_all('td')\n",
    "\n",
    "\n",
    "city_list = []\n",
    "country_list = []\n",
    "\n",
    "for td in td_tags:\n",
    "    a_tag = td.find('a', href=True)\n",
    "\n",
    "    if a_tag:\n",
    "        href = a_tag['href']  \n",
    "        parts = href.split('/')\n",
    "        if len(parts) == 4:\n",
    "            country = parts[2]  \n",
    "            city = parts[3].replace('-', ' ').title()  \n",
    "            country_list.append(country)\n",
    "            city_list.append(city)\n",
    "#print(country_list)\n",
    "#print(city_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9a71ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " id: 1, Country: Ghana, City: Accra\n",
      " id: 2, Country: Ireland, City: Dublin\n",
      " id: 3, Country: Kenya, City: Nairobi\n",
      " id: 4, Country: Ethiopia, City: Addis Ababa\n",
      " id: 5, Country: Canada, City: Edmonton\n",
      " id: 6, Country: Bahamas, City: Nassau\n",
      " id: 7, Country: Australia, City: Adelaide\n",
      " id: 8, Country: Germany, City: Frankfurt\n",
      " id: 9, Country: India, City: New Delhi\n",
      " id: 10, Country: Algeria, City: Algiers\n"
     ]
    }
   ],
   "source": [
    "matched_list = []\n",
    "id = 1\n",
    "\n",
    "for country, city in zip(country_list, city_list):\n",
    "    matched_list.append((id, country.title(), city.title()))\n",
    "    id += 1\n",
    "\n",
    "for entry in matched_list[:10]:\n",
    "    print(f\" id: {entry[0]}, Country: {entry[1]}, City: {entry[2]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ae6079e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ilk = soup.find_all('td')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "892a5ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 9, 22, 16, 15, 28, 12, 17, 37, 26, 18, 27, 24, 9, 17, 31, 29, 14, 15, 26, 13, 5, 26, 15, 7, 17, 22, 24, 30, 18, 24, 26, 28, 22, 24, 18, 26, 17, 5, 23, 35, 24, 12, 24, 39, 37, 31, 22, 30, 28, 17, 23, 23, 15, 24, 33, 28, 30, 26, 25, 24, 29, 5, 29, 28, 27, 17, 25, 22, 7, 28, 18, 16, 25, 25, 21, 41, 24, 20, 24, 28, 15, -2, 21, 23, 25, 9, 19, 37, 16, 15, 26, 23, 30, 15, 21, 17, 21, 29, 14, 12, 18, 16, 17, 32, 25, 18, 20, 23, 25, 33, 15, 33, 21, 15, 9, 18, 22, 16, 17, 30, 27, 17, 30, 13, 21, 11, 20, 19, 19, 14, 15, 26, 14, 29, 41, 20, 21, 38, 26, 15]\n"
     ]
    }
   ],
   "source": [
    "rbi_class = []\n",
    "rbi_c = soup.find_all('td', class_='rbi')\n",
    "\n",
    "\n",
    "for td in rbi_c:\n",
    "    temp_text = td.get_text(strip=True).replace('°C', '')  # '°C' sembolünü kaldır ve boşlukları temizle\n",
    "    rbi_class.append(int(temp_text))  # Değeri float tipine dönüştür ve listeye ekle\n",
    "\n",
    "# Listeyi yazdır\n",
    "print(rbi_class)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4368f999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwith open(\\'list_of_country.txt\\', \\'w\\') as file:\\n    for country, city, temp in zip(country_list, city_list, rbi_class):\\n        file.write(f\"Primary Key: {primary_key}, Country: {country.title()}, City: {city.title()}, Temp: {temp}°C\\n\")\\n        primary_key += 1\\n\\nprint(\"Succsesful\")\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#primary_key = 1\n",
    "\n",
    "# text\n",
    "\"\"\"\n",
    "with open('list_of_country.txt', 'w') as file:\n",
    "    for country, city, temp in zip(country_list, city_list, rbi_class):\n",
    "        file.write(f\"Primary Key: {primary_key}, Country: {country.title()}, City: {city.title()}, Temp: {temp}°C\\n\")\n",
    "        primary_key += 1\n",
    "\n",
    "print(\"successful\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5da60583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wed 10:29', 'Wed 11:29', 'Wed 13:29', 'Wed 13:29', 'Wed 04:29', 'Wed 06:29', 'Wed 19:59', 'Wed 12:29', 'Wed 15:59', 'Wed 11:29', 'Wed 04:29', 'Wed 05:29', 'Wed 15:29', 'Wed 07:29', 'Wed 06:29', 'Wed 13:29', 'Wed 17:29', 'Wed 12:29', 'Wed 12:29', 'Wed 12:29', 'Wed 06:29', 'Wed 22:29', 'Wed 06:29', 'Wed 12:29', 'Wed 02:29', 'Wed 13:29', 'Wed 18:29', 'Wed 13:29', 'Wed 18:29', 'Wed 06:29', 'Wed 13:29', 'Wed 00:29', 'Wed 03:29', 'Wed 06:29', 'Wed 05:29', 'Wed 12:29', 'Wed 13:29', 'Wed 06:29', 'Wed 10:29', 'Wed 06:29', 'Wed 15:29', 'Wed 07:29', 'Wed 22:29', 'Wed 13:29', 'Wed 13:29', 'Wed 13:29', 'Wed 17:29', 'Wed 12:29', 'Wed 17:29', 'Wed 13:29', 'Wed 04:29', 'Wed 12:29', 'Wed 12:29', 'Wed 03:29', 'Wed 18:29', 'Wed 15:29', 'Wed 06:29', 'Wed 13:29', 'Wed 16:14', 'Wed 04:29', 'Wed 12:29', 'Wed 05:29', 'Wed 07:29', 'Wed 15:59', 'Wed 11:29', 'Wed 06:29', 'Wed 12:29', 'Thu 00:29', 'Wed 07:29', 'Wed 05:29', 'Wed 15:59', 'Wed 03:29', 'Wed 06:29', 'Wed 18:29', 'Wed 19:29', 'Wed 07:29', 'Wed 13:29', 'Wed 18:29', 'Wed 20:29', 'Wed 13:29', 'Wed 18:29', 'Wed 12:29', 'Wed 06:29', 'Wed 13:29', 'Wed 13:29', 'Wed 11:29', 'Wed 07:59', 'Wed 12:29', 'Wed 15:29', 'Wed 12:29', 'Wed 07:29', 'Wed 03:29', 'Wed 22:29', 'Wed 13:29', 'Wed 05:29', 'Wed 20:29', 'Wed 04:29', 'Wed 11:29', 'Wed 18:29', 'Wed 20:29', 'Wed 11:29', 'Wed 13:29', 'Wed 12:29', 'Wed 03:29', 'Wed 15:29', 'Wed 06:29', 'Wed 12:29', 'Wed 04:29', 'Wed 11:29', 'Wed 04:29', 'Wed 13:59', 'Wed 05:29', 'Wed 18:29', 'Wed 19:29', 'Wed 12:29', 'Wed 20:29', 'Wed 06:29', 'Wed 05:29', 'Wed 04:29', 'Wed 03:29', 'Wed 13:29', 'Wed 06:29', 'Wed 12:29', 'Wed 19:59', 'Wed 05:29', 'Wed 12:29', 'Wed 04:29', 'Wed 13:29', 'Wed 06:29', 'Wed 06:29', 'Wed 07:29', 'Wed 05:29', 'Wed 16:29', 'Wed 06:29', 'Wed 16:59', 'Wed 13:29', 'Wed 13:29', 'Wed 12:29', 'Wed 14:29', 'Wed 15:59', 'Wed 12:29']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date = soup.find_all('td', class_='r')\n",
    "\n",
    "# Gün ve saat bilgilerini listeye ekle\n",
    "date_list = []\n",
    "\n",
    "for tag in date:\n",
    "    if tag.get_text(strip=True):  # Eğer <td> etiketi metin içeriyorsa (resim gibi boş değilse)\n",
    "        date_list.append(tag.get_text(strip=True))\n",
    "print(date_list)\n",
    "len(date_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11710dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://www.timeanddate.com\"\n",
    "links = soup.find_all('td')\n",
    "lst = []\n",
    "for link in links:\n",
    "    a_link = link.find('a', href=True)\n",
    "    if a_link:\n",
    "        full_link = base_url + a_link['href']\n",
    "        lst.append(full_link)\n",
    "\n",
    "        \n",
    "#print(lst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c37725ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1\n",
      "URL: https://www.timeanddate.com/weather/ghana/accra\n",
      "Feels Like: 30 °C\n",
      "Wind Speed: 10 km/h\n",
      "Humidity: 84%\n",
      "Dew Point: 24 °C\n",
      "Visibility: 6 km\n",
      "Probability of Precipitation: 49%\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "id: 2\n",
      "URL: https://www.timeanddate.com/weather/ireland/dublin\n",
      "Feels Like: 8 °C\n",
      "Wind Speed: 2 km/h\n",
      "Humidity: 85%\n",
      "Dew Point: 6 °C\n",
      "Visibility: 10 km\n",
      "Probability of Precipitation: 10%\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "id: 3\n",
      "URL: https://www.timeanddate.com/weather/kenya/nairobi\n",
      "Feels Like: 25 °C\n",
      "Wind Speed: 14 km/h\n",
      "Humidity: 43%\n",
      "Dew Point: 11 °C\n",
      "Visibility: 12 km\n",
      "Probability of Precipitation: 9%\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "id: 4\n",
      "URL: https://www.timeanddate.com/weather/ethiopia/addis-ababa\n",
      "Feels Like: 21 °C\n",
      "Wind Speed: 20 km/h\n",
      "Humidity: 60%\n",
      "Dew Point: 13 °C\n",
      "Visibility: 11 km\n",
      "Probability of Precipitation: 57%\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "id: 5\n",
      "URL: https://www.timeanddate.com/weather/canada/edmonton\n",
      "Feels Like: 14 °C\n",
      "Wind Speed: 12 km/h\n",
      "Humidity: 69%\n",
      "Dew Point: 9 °C\n",
      "Visibility: 11 km\n",
      "Probability of Precipitation: 0%\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "id: 6\n",
      "URL: https://www.timeanddate.com/weather/bahamas/nassau\n",
      "Feels Like: 34 °C\n",
      "Wind Speed: 26 km/h\n",
      "Humidity: 80%\n",
      "Dew Point: 25 °C\n",
      "Visibility: 7 km\n",
      "Probability of Precipitation: 43%\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "id: 7\n",
      "URL: https://www.timeanddate.com/weather/australia/adelaide\n",
      "Feels Like: 7 °C\n",
      "Wind Speed: 20 km/h\n",
      "Humidity: 67%\n",
      "Dew Point: 4 °C\n",
      "Visibility: 13 km\n",
      "Probability of Precipitation: 5%\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "id: 8\n",
      "URL: https://www.timeanddate.com/weather/germany/frankfurt\n",
      "Feels Like: 18 °C\n",
      "Wind Speed: 17 km/h\n",
      "Humidity: 74%\n",
      "Dew Point: 13 °C\n",
      "Visibility: 5 km\n",
      "Probability of Precipitation: 17%\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "id: 9\n",
      "URL: https://www.timeanddate.com/weather/india/new-delhi\n",
      "Feels Like: 42 °C\n",
      "Wind Speed: 8 km/h\n",
      "Humidity: 56%\n",
      "Dew Point: 25 °C\n",
      "Visibility: 13 km\n",
      "Probability of Precipitation: 0%\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "id: 10\n",
      "URL: https://www.timeanddate.com/weather/algeria/algiers\n",
      "Feels Like: 25 °C\n",
      "Wind Speed: 1 km/h\n",
      "Humidity: 59%\n",
      "Dew Point: 14 °C\n",
      "Visibility: 12 km\n",
      "Probability of Precipitation: 0%\n",
      "\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = ['Feels Like', 'Wind Speed', 'Humidity', 'Dew Point', 'Visibility', 'Probability of Precipitation']\n",
    "\n",
    "city_data = []\n",
    "\n",
    "for idx, url in enumerate(lst, start=1):  \n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    city_info = {\"id\": idx, \"url\": url}\n",
    "    rows = soup.find_all('tr')\n",
    "    \n",
    "    for row in rows:\n",
    "        th = row.find('th')\n",
    "        if th and th.get_text().strip() in labels:\n",
    "            td = row.find('td')\n",
    "            if td:\n",
    "                city_info[th.get_text().strip()] = td.get_text().strip()\n",
    "    \n",
    "    city_data.append(city_info)\n",
    "    \n",
    "for city in city_data[:10]:\n",
    "    print(f\"id: {city['id']}\")\n",
    "    print(f\"URL: {city['url']}\")\n",
    "    for label in labels:\n",
    "        print(f\"{label}: {city.get(label, 'N/A')}\")\n",
    "    print(\"\\n\" + \"-\"*40 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74bcbb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City data written to 'city_weather_data.txt'\n",
      "Country data with dates written to 'list_of_country.txt'\n"
     ]
    }
   ],
   "source": [
    "def write_data_with_dates(city_data, country_list, city_list, rbi_class, date_list, city_filename=\"city_weather_data.txt\", country_filename=\"list_of_country.txt\"):\n",
    "    id = 1\n",
    "\n",
    "    # Write city data\n",
    "    with open(city_filename, 'w') as city_file:\n",
    "        for city in city_data:\n",
    "            city_file.write(f\"id: {city['id']}\\n\")\n",
    "            city_file.write(f\"URL: {city['url']}\\n\")\n",
    "            for label in ['Feels Like', 'Wind Speed', 'Humidity', 'Dew Point', 'Visibility', 'Probability of Precipitation']:\n",
    "                city_file.write(f\"{label}: {city.get(label, 'N/A')}\\n\")\n",
    "            city_file.write(\"\\n\" + \"-\"*40 + \"\\n\")\n",
    "        print(f\"City data written to '{city_filename}'\")\n",
    "\n",
    "    # Write country, city, temp, and date data\n",
    "    with open(country_filename, 'w') as country_file:\n",
    "        for country, city, temp, date in zip(country_list, city_list, rbi_class, date_list):\n",
    "            country_file.write(f\"id: {id}, Country: {country.title()}, City: {city.title()}, Temp: {temp}°C, Date: {date}\\n\")\n",
    "            id += 1\n",
    "        print(f\"Country data with dates written to '{country_filename}'\")\n",
    "write_data_with_dates(city_data, country_list, city_list, rbi_class, date_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ee0b19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files moved to 'Data/txt_files'\n"
     ]
    }
   ],
   "source": [
    "def move_files_to_folder(city_filename=\"city_weather_data.txt\", country_filename=\"list_of_country.txt\", folder_path=\"Data/txt_files\"):\n",
    "    # Eğer klasör yoksa, oluştur\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    try:\n",
    "        # Dosyaları belirtilen klasöre taşı\n",
    "        shutil.move(city_filename, os.path.join(folder_path, city_filename))\n",
    "        shutil.move(country_filename, os.path.join(folder_path, country_filename))\n",
    "        print(f\"Files moved to '{folder_path}'\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "move_files_to_folder()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
